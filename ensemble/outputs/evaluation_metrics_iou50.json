{
  "dataset_info": {
    "total_images": 60,
    "total_ground_truth_boxes": 482,
    "total_predicted_boxes": 507,
    "iou_threshold": 0.5
  },
  "per_class_metrics": {
    "date_of_reciept": {
      "precision": 0.95,
      "recall": 0.9828,
      "f1_score": 0.9661,
      "average_iou": 0.8344,
      "true_positives": 57,
      "false_positives": 3,
      "false_negatives": 1,
      "total_ground_truth": 58,
      "total_predictions": 60
    },
    "gstin": {
      "precision": 0.8704,
      "recall": 0.8246,
      "f1_score": 0.8468,
      "average_iou": 0.8271,
      "true_positives": 47,
      "false_positives": 7,
      "false_negatives": 10,
      "total_ground_truth": 57,
      "total_predictions": 54
    },
    "invoice_no": {
      "precision": 0.918,
      "recall": 0.9655,
      "f1_score": 0.9412,
      "average_iou": 0.8143,
      "true_positives": 56,
      "false_positives": 5,
      "false_negatives": 2,
      "total_ground_truth": 58,
      "total_predictions": 61
    },
    "mobile_no": {
      "precision": 0.6176,
      "recall": 0.7368,
      "f1_score": 0.672,
      "average_iou": 0.7932,
      "true_positives": 42,
      "false_positives": 26,
      "false_negatives": 15,
      "total_ground_truth": 57,
      "total_predictions": 68
    },
    "product_table": {
      "precision": 0.9437,
      "recall": 0.9853,
      "f1_score": 0.964,
      "average_iou": 0.9001,
      "true_positives": 67,
      "false_positives": 4,
      "false_negatives": 1,
      "total_ground_truth": 68,
      "total_predictions": 71
    },
    "store_address": {
      "precision": 0.8906,
      "recall": 0.9828,
      "f1_score": 0.9344,
      "average_iou": 0.847,
      "true_positives": 57,
      "false_positives": 7,
      "false_negatives": 1,
      "total_ground_truth": 58,
      "total_predictions": 64
    },
    "store_name": {
      "precision": 0.9706,
      "recall": 0.9706,
      "f1_score": 0.9706,
      "average_iou": 0.8548,
      "true_positives": 66,
      "false_positives": 2,
      "false_negatives": 2,
      "total_ground_truth": 68,
      "total_predictions": 68
    },
    "total_amount": {
      "precision": 0.9344,
      "recall": 0.9828,
      "f1_score": 0.958,
      "average_iou": 0.8305,
      "true_positives": 57,
      "false_positives": 4,
      "false_negatives": 1,
      "total_ground_truth": 58,
      "total_predictions": 61
    }
  },
  "overall_metrics": {
    "precision": 0.8856,
    "recall": 0.9315,
    "f1_score": 0.908,
    "macro_precision": 0.8869,
    "macro_recall": 0.9289,
    "macro_f1": 0.9066,
    "mean_iou": 0.8377,
    "detection_accuracy": 0.8315
  }
}