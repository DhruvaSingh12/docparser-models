{
  "dataset_info": {
    "total_images": 60,
    "total_ground_truth_boxes": 482,
    "total_predicted_boxes": 507,
    "iou_threshold": 0.95
  },
  "per_class_metrics": {
    "date_of_reciept": {
      "precision": 0.05,
      "recall": 0.0517,
      "f1_score": 0.0508,
      "average_iou": 0.9553,
      "true_positives": 3,
      "false_positives": 57,
      "false_negatives": 55,
      "total_ground_truth": 58,
      "total_predictions": 60
    },
    "gstin": {
      "precision": 0.0185,
      "recall": 0.0175,
      "f1_score": 0.018,
      "average_iou": 0.9504,
      "true_positives": 1,
      "false_positives": 53,
      "false_negatives": 56,
      "total_ground_truth": 57,
      "total_predictions": 54
    },
    "invoice_no": {
      "precision": 0.0,
      "recall": 0.0,
      "f1_score": 0.0,
      "average_iou": 0.0,
      "true_positives": 0,
      "false_positives": 61,
      "false_negatives": 58,
      "total_ground_truth": 58,
      "total_predictions": 61
    },
    "mobile_no": {
      "precision": 0.0,
      "recall": 0.0,
      "f1_score": 0.0,
      "average_iou": 0.0,
      "true_positives": 0,
      "false_positives": 68,
      "false_negatives": 57,
      "total_ground_truth": 57,
      "total_predictions": 68
    },
    "product_table": {
      "precision": 0.1972,
      "recall": 0.2059,
      "f1_score": 0.2014,
      "average_iou": 0.9638,
      "true_positives": 14,
      "false_positives": 57,
      "false_negatives": 54,
      "total_ground_truth": 68,
      "total_predictions": 71
    },
    "store_address": {
      "precision": 0.0469,
      "recall": 0.0517,
      "f1_score": 0.0492,
      "average_iou": 0.9652,
      "true_positives": 3,
      "false_positives": 61,
      "false_negatives": 55,
      "total_ground_truth": 58,
      "total_predictions": 64
    },
    "store_name": {
      "precision": 0.0294,
      "recall": 0.0294,
      "f1_score": 0.0294,
      "average_iou": 0.9603,
      "true_positives": 2,
      "false_positives": 66,
      "false_negatives": 66,
      "total_ground_truth": 68,
      "total_predictions": 68
    },
    "total_amount": {
      "precision": 0.0164,
      "recall": 0.0172,
      "f1_score": 0.0168,
      "average_iou": 0.9728,
      "true_positives": 1,
      "false_positives": 60,
      "false_negatives": 57,
      "total_ground_truth": 58,
      "total_predictions": 61
    }
  },
  "overall_metrics": {
    "precision": 0.0473,
    "recall": 0.0498,
    "f1_score": 0.0485,
    "macro_precision": 0.0448,
    "macro_recall": 0.0467,
    "macro_f1": 0.0457,
    "mean_iou": 0.9613,
    "detection_accuracy": 0.0249
  }
}